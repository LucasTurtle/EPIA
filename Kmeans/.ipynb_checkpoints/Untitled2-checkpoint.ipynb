{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  35.  148.   17.]\n",
      "1.63353864779\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 200 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 200 samples in 0.002s...\n",
      "[t-SNE] Computed conditional probabilities for sample 200 / 200\n",
      "[t-SNE] Mean sigma: 0.300441\n",
      "[t-SNE] Computed conditional probabilities in 0.010s\n",
      "[t-SNE] Iteration 50: error = 71.2095642, gradient norm = 0.5728805 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 100: error = 73.3568344, gradient norm = 0.4342892 (50 iterations in 0.152s)\n",
      "[t-SNE] Iteration 150: error = 82.0390778, gradient norm = 0.3800326 (50 iterations in 0.128s)\n",
      "[t-SNE] Iteration 200: error = 77.4708939, gradient norm = 0.4338547 (50 iterations in 0.149s)\n",
      "[t-SNE] Iteration 250: error = 74.9379501, gradient norm = 0.4765946 (50 iterations in 0.145s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 74.937950\n",
      "[t-SNE] Iteration 300: error = 1.8180430, gradient norm = 0.0104744 (50 iterations in 0.136s)\n",
      "[t-SNE] Iteration 350: error = 1.4171731, gradient norm = 0.0058860 (50 iterations in 0.125s)\n",
      "[t-SNE] Iteration 400: error = 1.3488966, gradient norm = 0.0030765 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 450: error = 1.2732540, gradient norm = 0.0028811 (50 iterations in 0.124s)\n",
      "[t-SNE] Iteration 500: error = 1.0515628, gradient norm = 0.0097956 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 550: error = 0.8575292, gradient norm = 0.0078005 (50 iterations in 0.124s)\n",
      "[t-SNE] Iteration 600: error = 0.8248686, gradient norm = 0.0012552 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 650: error = 0.8135726, gradient norm = 0.0018355 (50 iterations in 0.125s)\n",
      "[t-SNE] Iteration 700: error = 0.8072693, gradient norm = 0.0010251 (50 iterations in 0.130s)\n",
      "[t-SNE] Iteration 750: error = 0.8031941, gradient norm = 0.0008886 (50 iterations in 0.127s)\n",
      "[t-SNE] Iteration 800: error = 0.7989404, gradient norm = 0.0004997 (50 iterations in 0.128s)\n",
      "[t-SNE] Iteration 850: error = 0.7986191, gradient norm = 0.0001856 (50 iterations in 0.122s)\n",
      "[t-SNE] Iteration 900: error = 0.7981533, gradient norm = 0.0006403 (50 iterations in 0.127s)\n",
      "[t-SNE] Iteration 950: error = 0.7982442, gradient norm = 0.0003207 (50 iterations in 0.123s)\n",
      "[t-SNE] Iteration 1000: error = 0.7975312, gradient norm = 0.0003896 (50 iterations in 0.125s)\n",
      "[t-SNE] Error after 1000 iterations: 0.797531\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas de estruturas de dados e manipulação algébrica\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# bibliotecas de projeção\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Carrego uma tabela num dataframe\n",
    "def loadData(path):\n",
    "\tdf = pd.read_csv(path, sep='\\t', dtype = float, index_col=False)\n",
    "\treturn df\n",
    "\n",
    "# Retorna o valor mais alto de um dataframe\n",
    "def highestValue(df):\n",
    "\tseriesHighest = df.max(numeric_only=True)\n",
    "\treturn seriesHighest.max()\n",
    "\n",
    "def euclideanDistance(a, b):\n",
    "\tresult = 0\n",
    "\tfor i in range (0, len(a)):\n",
    "\t\tresult += ((a[i] - b[i]) ** 2)\n",
    "\treturn (result ** (1/2))\n",
    "\n",
    "def cosineSimilarity(a, b):\n",
    "\tprodEscalar = np.inner(a, b)\n",
    "\t(magnitudeA, magnitudeB) = 0, 0\n",
    "\tfor i in range (0, len(a)):\n",
    "\t\tmagnitudeA += a[i] ** 2\n",
    "\t\tmagnitudeB += b[i] ** 2\n",
    "\tmagnitudeA = magnitudeA ** (1/2)\n",
    "\tmagnitudeB = magnitudeB ** (1/2)\n",
    "\treturn (prodEscalar/(magnitudeA * magnitudeB))\n",
    "\n",
    "# Acha a distancia entre um ponto e o seu centroide mais próximo\n",
    "def distanceFromClosestCentroid(centroids, point):\n",
    "\tmin_dist = float(\"inf\")\n",
    "\tfor centroid in centroids:\n",
    "\t\t# Se ainda não houver sido calculado o centroide (todos os valores dele forem 0), passe para a próxima iteração\n",
    "\t\tif (~centroid.any(axis=0)).any():\n",
    "\t\t\tcontinue\n",
    "\t\tdist = euclideanDistance(centroid, point)\n",
    "\t\tmin_dist = dist if dist < min_dist else min_dist\n",
    "\treturn min_dist\n",
    "\n",
    "# Fitness Proportionate Selection\n",
    "def rouletteWheel(distances, totalPoints):\n",
    "\tcumulativeProb = distances/np.sum(distances)\n",
    "\tp = np.random.random_sample()\n",
    "\tsum = 0\n",
    "\tfor i in range (0, totalPoints):\n",
    "\t\tif p <= sum:\n",
    "\t\t\treturn i\n",
    "\t\tsum += cumulativeProb[i]\n",
    "\n",
    "# inicialização kmeans++\n",
    "def smartCentroids(max_clusters, df):\n",
    "\ttotalPoints = len(df)\n",
    "\trandomPoint = np.random.randint(0, totalPoints) # indice do ponto aleatório\n",
    "\n",
    "\tsmartCentroids = np.zeros([max_clusters, len(df.columns)], dtype = float)\n",
    "\tsmartCentroids[0] = df.iloc[randomPoint] # centroide designado no ponto aleatório\n",
    "\n",
    "\t# distancia quadrada entre o ponto e o seu centroide mais próximo \n",
    "\tdistances = np.full(totalPoints, -1, dtype = float)\n",
    "\tfor i in range(1, max_clusters):\n",
    "\t\tfor j in range (0, totalPoints):\n",
    "\t\t\tpoint = df.values[j]\n",
    "\t\t\tdistances[j] = distanceFromClosestCentroid(smartCentroids, point) ** 2\n",
    "\t\t\n",
    "\t\tindex = rouletteWheel(distances, totalPoints) # indice do novo centroide\n",
    "\t\tsmartCentroids[i] = df.iloc[index]\n",
    "\treturn smartCentroids\n",
    "\n",
    "# Retorna uma lista em que cada linha é um centroide inicializado com valores random\n",
    "def randomCentroids(max_clusters, df):\n",
    "\tmaxValue = highestValue(df)\n",
    "\tcolumns = len(df.columns)\n",
    "\trandCentroids = np.zeros([max_clusters, columns], dtype = float)\n",
    "\tfor i in range(0, max_clusters):\n",
    "\t\tfor j in range(0, columns):\n",
    "\t\t\trandCentroids[i][j] = round(random.uniform(0, maxValue), 4) # coordenada de valor float aleatorio com 4 casas decimais de precisão\n",
    "\treturn randCentroids\n",
    "\n",
    "# retorna qual a distancia de cada elemento para cada cluster e quantos elementos existem em cada cluster\n",
    "def calculateClusters(df, centroids):\n",
    "\tclusters = np.full((df.shape[0], max_clusters), -1).astype(float)\n",
    "\telements_in_cluster = np.zeros(shape=[max_clusters])\n",
    "\tdoc_in_cluster = np.zeros((df.shape[0], 2), dtype = float) # em que cluster está tal doc, e qual a distancia do doc ao cluster\n",
    "\n",
    "\tfor i in range(df.shape[0]):       \n",
    "\t\tdoc = df.values[i]     # coordenada de um doc    \n",
    "\t\tcentroid_index = 0\n",
    "\t\tmin_dist = float(\"inf\")\n",
    "\n",
    "\t\t# acha o centroide mais próximo de um ponto\n",
    "\t\tfor centroid in centroids:\n",
    "\t\t\tdist =  euclideanDistance(centroid, doc) #np.linalg.norm(centroid - doc)\n",
    "\t\t\tif (dist < min_dist):\n",
    "\t\t\t\tmin_dist = dist\n",
    "\t\t\t\tmin_dist_index = centroid_index\n",
    "\t\t\tcentroid_index += 1\n",
    "\n",
    "\t\tclusters[i][min_dist_index] = min_dist\n",
    "\t\telements_in_cluster[min_dist_index] += 1\n",
    "\t\tdoc_in_cluster[i][0] = min_dist_index\n",
    "\t\tdoc_in_cluster[i][1] = min_dist\n",
    "\treturn (clusters, elements_in_cluster, doc_in_cluster)\n",
    "\n",
    "# recalcula a nova posição dos centroides, os movendo para o centro de seu grupo\n",
    "def recalculateCentroids(df, max_clusters, centroids, clusters, elements_in_cluster):\n",
    "\ttotal_docs = clusters.shape[0]\n",
    "\ttotal_words = df.shape[1]\n",
    "\tnew_centroids = np.zeros([max_clusters, total_words], dtype = float)\n",
    "\n",
    "\t# move o centroide para a posição média em seu cluster\n",
    "\tfor i in range(0, total_docs):\n",
    "\t\tfor j in range(0, max_clusters):\n",
    "\t\t\tif clusters[i][j] != -1:\n",
    "\t\t\t\tfor k in range(0, total_words):\n",
    "\t\t\t\t\tnew_centroids[j][k] += df.iloc[i][k] / elements_in_cluster[j]\n",
    "\n",
    "\t\t\t# se um cluster não tiver nenhum elemento, não movemos o centroide\n",
    "\t\t\tif (elements_in_cluster[j] == 0):\n",
    "\t\t\t\tnew_centroids[j] = centroids[j]\n",
    "\treturn new_centroids\n",
    "\n",
    "# dada a matriz de cluters e posições, retorna somente o cluster desejado\n",
    "def getCluster(allClusters, cluster_index, df):\n",
    "\tallClusters = pd.DataFrame(allClusters)\n",
    "\tcluster = allClusters.loc[allClusters[cluster_index] != -1]\n",
    "\t\n",
    "\theader_list = list(range(0, len(df.columns)))\n",
    "\tresult = pd.DataFrame(columns=header_list)\n",
    "\n",
    "\tfor index, row in cluster.iterrows():\n",
    "\t\tresult.loc[index] = df.loc[index].values\n",
    "\treturn result\n",
    "\n",
    "\n",
    "# calcula o indice silhouette\n",
    "def silhouette (clusters, centroids, df, doc_in_cluster):\n",
    "\ttotal_elements = len(clusters)\n",
    "\ttotal_clusters = len(centroids)\n",
    "\tsilhouette = np.zeros((total_elements, total_clusters))\n",
    "\n",
    "\tfor i in range(0, max_clusters):\n",
    "\t\tcluster = getCluster(clusters, i, df).round(4)\n",
    "\t\tfor index, value in cluster.iterrows():\n",
    "\t\t\ta, b = (0, 0)\n",
    "\n",
    "\t\t\t# calcula a distancia média de um elemento pros outros elementos\n",
    "\t\t\tfor jindex, value in cluster.iterrows():\n",
    "\t\t\t\ta += euclideanDistance (cluster.loc[index].values, cluster.loc[jindex].values)\n",
    "\t\t\t\n",
    "\t\t\t# se o cluster só tiver um elemento, eu calculo sua distancia com o centroide do seu grupo \n",
    "\t\t\tif (len(cluster) == 1):\n",
    "\t\t\t\ta = euclideanDistance (cluster.loc[index].values, centroids[i])\n",
    "\t\t\telse:\n",
    "\t\t\t\ta = a/(len(cluster)-1)\n",
    "\n",
    "\t\t\tmin_b = float(\"inf\")\n",
    "\t\t\t# calcula a distancia minima de um elemento pros elementos de outros clusters\n",
    "\t\t\tfor j in range (0, total_clusters):\n",
    "\t\t\t\tif (j == i): continue\n",
    "\t\t\t\totherCluster = getCluster(clusters, j, df).round(4)\n",
    "\n",
    "\t\t\t\t# Se o outro cluster for vazio, eu calculo a distancia dos elementos deste cluster com os outros centroides\n",
    "\t\t\t\tif not otherCluster.empty:\t\t\n",
    "\t\t\t\t\tfor jindex, value in otherCluster.iterrows():\n",
    "\t\t\t\t\t\tb += euclideanDistance (cluster.loc[index].values, otherCluster.loc[jindex].values)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tb += euclideanDistance (cluster.loc[index].values, centroids[j])\n",
    "\t\t\tb = b/len(otherCluster)\n",
    "\t\t\tif (b < min_b): min_b = b\n",
    "\t\t\tprint (index)\n",
    "\n",
    "\t\t\tsilhouette[index][0] = (min_b-a)/max(a, min_b)\n",
    "\t\t\tsilhouette[index][1] = i\n",
    "\tprint (silhouette)\n",
    "\n",
    "# define a qual cluster tal documento faz parte\n",
    "def assignCluster(clusteredDF, doc_in_cluster):\n",
    "\tdoc_in_cluster = pd.Series(doc_in_cluster[:, 0])\n",
    "\treturn df.assign(Cluster=doc_in_cluster)\n",
    "\n",
    "# criamos um scatter plot 3D para a visualização dos dados\n",
    "def matPlot3D(df):\n",
    "\tfig = plt.figure()\n",
    "\tax = fig.add_subplot(111, projection='3d')\n",
    "\tx = np.array(df['PCA1'])\n",
    "\ty = np.array(df['PCA2'])\n",
    "\tz = np.array(df['PCA3'])\n",
    "\tax.scatter(x,y,z, marker=\"s\", c=df[\"Cluster\"], s=20, cmap=\"Dark2\", depthshade=False)\n",
    "\tax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))\n",
    "\tplt.show()\n",
    "\t# viridis, Dark2\n",
    "\n",
    "# Acha a magnitude dos centroides e retorna a variação de distancia entre eles\n",
    "def errorFunction(old_centroids, new_centroids):\n",
    "\tmagnitudeA, magnitudeB = (0, 0)\n",
    "\tfor i in range (0, len(old_centroids)):\n",
    "\t\tmagnitudeA += old_centroids[i] ** 2\n",
    "\t\tmagnitudeB += new_centroids[i] ** 2\n",
    "\tmagnitudeA = magnitudeA ** (1/2)\n",
    "\tmagnitudeB = magnitudeB ** (1/2)\n",
    "\treturn euclideanDistance(magnitudeA, magnitudeB)\n",
    "\n",
    "def kmeans(df, max_clusters, max_iterations, threshold):\n",
    "\tcentroids = smartCentroids(max_clusters, df)\n",
    "\titers = 0\n",
    "\n",
    "\twhile iters < max_iterations:\n",
    "\t\t#print(\"iteration: \", iters)\n",
    "\t\t(clusters, elements_in_cluster, doc_in_cluster) = calculateClusters(df, centroids)\n",
    "\t\t#print (clusters)\n",
    "\n",
    "\t\t#silhouette(clusters, centroids, df, doc_in_cluster)\n",
    "\t\t\n",
    "\t\t#if iters == 0:  matPlot3D(df, doc_in_cluster)\n",
    "\n",
    "\t\tnew_centroids = recalculateCentroids(df, max_clusters, centroids, clusters, elements_in_cluster)\n",
    "\t\terror = errorFunction(centroids, new_centroids)\n",
    "\t\t#print (np.linalg.norm(centroids - new_centroids))\n",
    "\t\tprint (elements_in_cluster)\n",
    "\t\tprint (error)\n",
    "\t\t#print (doc_in_cluster)\n",
    "\t\tif (error <= threshold):\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tcentroids = new_centroids\n",
    "\t\titers += 1\n",
    "\n",
    "\treturn doc_in_cluster\n",
    "\n",
    "# normaliza os dados com valores de 0 a 1\n",
    "def normalize(df):\n",
    "\tmin_max_scaler = preprocessing.MinMaxScaler()\n",
    "\tnp_scaled = min_max_scaler.fit_transform(df)\n",
    "\treturn pd.DataFrame(np_scaled, columns = ['PCA1', 'PCA2', 'PCA3'])\n",
    "\n",
    "\n",
    "def reduceDimensions(data, dims):\n",
    "\tX_reduced = TruncatedSVD(n_components=50, random_state=0).fit_transform(data)\n",
    "\tX_embedded = TSNE(n_components=dims, perplexity=40, verbose=2).fit_transform(X_reduced)\n",
    "\tX_embedded = pd.DataFrame(X_embedded)\n",
    "\treturn X_embedded\n",
    "\n",
    "def visualize(data):\n",
    "\tfig = plt.figure(figsize=(10, 10))\n",
    "\tax = plt.axes(frameon=False)\n",
    "\tplt.setp(ax, xticks=(), yticks=())\n",
    "\tplt.subplots_adjust(left=0.0, bottom=0.0, right=1.0, top=0.9,\n",
    "\t\t\t\t\twspace=0.0, hspace=0.0)\n",
    "\tplt.scatter(data[:, 0], data[:, 1], marker=\"x\") #c=twenty_dataset.target\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "path = '../pre_process/processedSmall/tfidf.tsv'\n",
    "df = pd.read_csv(path, sep='\\t', index_col=0)\n",
    "#df = pd.DataFrame(np.random.uniform(0, 500, size = (5000, 5)))\n",
    "\n",
    "max_clusters = 3\n",
    "max_iterations = 1\n",
    "threshold = 0.2\n",
    "\n",
    "doc_in_cluster = kmeans(df, max_clusters, max_iterations, threshold)\n",
    "df = reduceDimensions(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      1.3857]\n",
      " [ 1.      1.245 ]\n",
      " [ 1.      1.3533]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.3789]\n",
      " [ 1.      1.394 ]\n",
      " [ 2.      1.3987]\n",
      " [ 1.      1.3908]\n",
      " [ 1.      1.3224]\n",
      " [ 1.      1.4033]\n",
      " [ 0.      1.4074]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3896]\n",
      " [ 1.      1.4109]\n",
      " [ 2.      1.3917]\n",
      " [ 1.      1.3784]\n",
      " [ 1.      1.4025]\n",
      " [ 1.      1.4075]\n",
      " [ 1.      1.3861]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3891]\n",
      " [ 1.      1.3365]\n",
      " [ 1.      1.    ]\n",
      " [ 1.      1.371 ]\n",
      " [ 1.      1.3668]\n",
      " [ 1.      1.3194]\n",
      " [ 1.      1.3646]\n",
      " [ 1.      1.3628]\n",
      " [ 1.      1.406 ]\n",
      " [ 1.      1.    ]\n",
      " [ 2.      1.4025]\n",
      " [ 0.      1.382 ]\n",
      " [ 1.      1.4041]\n",
      " [ 2.      1.3902]\n",
      " [ 1.      1.4045]\n",
      " [ 1.      1.3978]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3711]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.    ]\n",
      " [ 0.      1.3751]\n",
      " [ 1.      1.4003]\n",
      " [ 1.      1.3987]\n",
      " [ 1.      1.3867]\n",
      " [ 1.      1.3653]\n",
      " [ 0.      1.3566]\n",
      " [ 2.      1.3489]\n",
      " [ 2.      1.3867]\n",
      " [ 2.      1.3764]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.384 ]\n",
      " [ 0.      1.2013]\n",
      " [ 0.      1.374 ]\n",
      " [ 1.      1.3974]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.3204]\n",
      " [ 1.      1.3725]\n",
      " [ 1.      1.3913]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4025]\n",
      " [ 1.      1.3708]\n",
      " [ 1.      1.3796]\n",
      " [ 0.      1.3682]\n",
      " [ 1.      1.3939]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.3961]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4084]\n",
      " [ 1.      1.3027]\n",
      " [ 2.      1.4034]\n",
      " [ 0.      1.4027]\n",
      " [ 1.      1.3494]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.3887]\n",
      " [ 1.      1.3153]\n",
      " [ 1.      1.3827]\n",
      " [ 1.      1.4065]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.3908]\n",
      " [ 1.      1.2786]\n",
      " [ 1.      1.4027]\n",
      " [ 1.      1.3907]\n",
      " [ 1.      1.3868]\n",
      " [ 1.      1.3885]\n",
      " [ 2.      1.3795]\n",
      " [ 0.      1.4084]\n",
      " [ 1.      1.4002]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4099]\n",
      " [ 1.      1.4048]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3888]\n",
      " [ 0.      1.3869]\n",
      " [ 0.      1.3999]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3817]\n",
      " [ 1.      1.3901]\n",
      " [ 1.      1.3663]\n",
      " [ 1.      1.4044]\n",
      " [ 1.      1.4056]\n",
      " [ 1.      1.3927]\n",
      " [ 2.      1.3845]\n",
      " [ 1.      1.3767]\n",
      " [ 0.      1.357 ]\n",
      " [ 0.      1.379 ]\n",
      " [ 1.      1.3948]\n",
      " [ 0.      1.3212]\n",
      " [ 2.      1.3923]\n",
      " [ 1.      1.4023]\n",
      " [ 1.      1.3996]\n",
      " [ 1.      1.3675]\n",
      " [ 1.      1.4094]\n",
      " [ 1.      1.3739]\n",
      " [ 1.      1.3994]\n",
      " [ 1.      1.4059]\n",
      " [ 1.      1.3865]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.4038]\n",
      " [ 1.      1.3465]\n",
      " [ 1.      1.4142]\n",
      " [ 2.      0.    ]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3589]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.4044]\n",
      " [ 1.      1.3911]\n",
      " [ 1.      1.4074]\n",
      " [ 1.      1.3755]\n",
      " [ 2.      1.386 ]\n",
      " [ 0.      1.3806]\n",
      " [ 2.      1.3426]\n",
      " [ 0.      1.3542]\n",
      " [ 2.      1.3898]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3858]\n",
      " [ 1.      1.3829]\n",
      " [ 0.      1.3449]\n",
      " [ 1.      1.4025]\n",
      " [ 2.      1.3986]\n",
      " [ 1.      1.3887]\n",
      " [ 1.      1.4044]\n",
      " [ 0.      1.407 ]\n",
      " [ 1.      1.4047]\n",
      " [ 1.      1.3541]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4081]\n",
      " [ 1.      1.4142]\n",
      " [ 0.      1.3827]\n",
      " [ 0.      1.3776]\n",
      " [ 1.      1.4062]\n",
      " [ 1.      1.3878]\n",
      " [ 0.      0.    ]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      0.    ]\n",
      " [ 0.      1.2714]\n",
      " [ 1.      1.3341]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3841]\n",
      " [ 1.      1.3815]\n",
      " [ 1.      1.3898]\n",
      " [ 1.      1.3531]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3622]\n",
      " [ 2.      1.3172]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3495]\n",
      " [ 1.      1.3811]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3951]\n",
      " [ 1.      1.3491]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.4048]\n",
      " [ 1.      1.3847]\n",
      " [ 1.      1.4114]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3776]\n",
      " [ 0.      1.4066]\n",
      " [ 0.      1.3563]\n",
      " [ 1.      1.3623]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3715]\n",
      " [ 0.      1.39  ]\n",
      " [ 1.      1.3901]\n",
      " [ 1.      1.3465]\n",
      " [ 1.      1.3714]\n",
      " [ 1.      1.4047]\n",
      " [ 1.      1.3896]\n",
      " [ 1.      1.4036]\n",
      " [ 0.      1.3983]\n",
      " [ 1.      1.4085]\n",
      " [ 1.      1.4142]\n",
      " [ 1.      1.3797]\n",
      " [ 0.      1.4051]\n",
      " [ 1.      1.    ]\n",
      " [ 1.      1.373 ]\n",
      " [ 1.      1.4078]\n",
      " [ 1.      1.323 ]\n",
      " [ 1.      1.4009]]\n"
     ]
    }
   ],
   "source": [
    "print (doc_in_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assign(Cluster=doc_in_cluster[:, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
